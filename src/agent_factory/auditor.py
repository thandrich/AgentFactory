import logging
from typing import Dict, Any, Union
import json
import os
import google.generativeai as genai
from dotenv import load_dotenv
import logging
import json
import asyncio
from typing import Dict, Any, Union
from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner

logger = logging.getLogger("Auditor")

class Auditor:
    """
    The Auditor agent is responsible for reviewing the generated code
    against the blueprint and safety guidelines.
    """

    def __init__(self, model_name: str = "gemini-2.5-flash"):
        self.model_name = model_name
        self.model_config = Gemini(model=model_name)
        
        self.system_instruction = """
        You are The Auditor, a senior code reviewer and security expert.
        Your goal is to review Python code generated by The Engineer against a Blueprint designed by The Architect.
        
        Review Criteria:
        1. **Functionality**: Does the code implement the tools and logic described in the Blueprint?
        2. **Safety**: Are there any security vulnerabilities (e.g., API key leaks, unsafe exec/eval, infinite loops)?
        3. **ADK Compliance**: Does the code strictly follow the ADK syntax (LlmAgent, InMemoryRunner, Gemini)?
        4. **Quality**: Is the code clean, well-documented, and error-free?
        
        Output strictly valid JSON with the following structure:
        {
            "approved": true/false,
            "issues": [
                "Critical: Description of critical issue",
                "Major: Description of major issue",
                "Minor: Description of minor issue"
            ],
            "suggestions": [
                "Suggestion for improvement"
            ]
        }
        
        If "approved" is true, the code is ready for deployment.
        If "approved" is false, "issues" must contain specific reasons.
        """
        
        self.agent = LlmAgent(
            name="Auditor",
            model=self.model_config,
            instruction=self.system_instruction
        )
        self.runner = InMemoryRunner(agent=self.agent)
        logger.info(f"Auditor initialized with model: {model_name}")

    def review_code(self, code: str, blueprint: Dict[str, Any]) -> Union[bool, Dict[str, Any]]:
        """
        Reviews the code against the blueprint.
        Returns True if approved, or a dictionary with feedback if rejected.
        """
        logger.info("Auditor reviewing code...")
        
        prompt = f"""
        Blueprint:
        {json.dumps(blueprint, indent=2)}
        
        Generated Code:
        ```python
        {code}
        ```
        
        Review the code now.
        """
        
        async def _run():
            events = await self.runner.run_debug(prompt)
            for event in reversed(events):
                if hasattr(event, 'content') and event.content and event.content.parts:
                    for part in event.content.parts:
                        if part.text:
                            return part.text
            return ""

        try:
            response_text = asyncio.run(_run())
            
            # Clean up markdown
            cleaned_text = response_text.strip()
            if cleaned_text.startswith("```json"):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.startswith("```"):
                cleaned_text = cleaned_text[3:]
            if cleaned_text.endswith("```"):
                cleaned_text = cleaned_text[:-3]
            
            review = json.loads(cleaned_text.strip())
            
            if review.get("approved"):
                return True
            else:
                return review
                
        except Exception as e:
            logger.error(f"Error reviewing code: {e}")
            # Fail safe: reject if we can't parse
            return {
                "approved": False,
                "issues": [f"Auditor failed to parse review: {e}"],
                "suggestions": ["Retry review"]
            }

    def review_agent(self, code: str, agent_definition: Dict[str, Any]) -> Dict[str, str]:
        """
        Reviews the agent code against the agent definition.
        Returns a standardized result dictionary matching QA Lead's interface.
        
        Args:
            code: The Python source code to review
            agent_definition: The agent definition dict from the Architect's blueprint
            
        Returns:
            Dict with keys: status ("PASS"/"FAIL"), reasoning, feedback (optional)
        """
        logger.info(f"Auditor reviewing agent: {agent_definition.get('agent_name', 'Unknown')}")
        
        result = self.review_code(code, agent_definition)
        
        # Convert boolean/dict result to standardized format
        if result is True:
            return {
                "status": "PASS",
                "reasoning": "Code passed all review criteria.",
                "feedback": ""
            }
        elif isinstance(result, dict):
            issues_str = "\n".join(result.get("issues", []))
            suggestions_str = "\n".join(result.get("suggestions", []))
            
            return {
                "status": "FAIL",
                "reasoning": issues_str if issues_str else "Code failed review.",
                "feedback": suggestions_str
            }
        else:
            # Unexpected format
            return {
                "status": "FAIL",
                "reasoning": "Auditor returned unexpected result format.",
                "feedback": "Please retry the review."
            }
